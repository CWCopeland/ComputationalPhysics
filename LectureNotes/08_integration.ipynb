{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4XnWii6Xm1Ff",
   "metadata": {
    "id": "4XnWii6Xm1Ff"
   },
   "source": [
    "# Integration with Python - Part A - Introduction\n",
    "\n",
    "$\\newcommand{\\d}{\\mathrm{d}}$\n",
    "$\\newcommand{\\p}{^{\\prime}}$\n",
    "\n",
    "While many integrals can be evaluated analytically, there are far more that lack a closed-form solution.  For such integrals, we are forced to resort to numerical techniques.  \n",
    "\n",
    "As a reminder, the value of the integral of a function $f(x)$ from $x=a$ to $x=b$, $I(a,b)=\\int_a^bf(x)\\d x$, is given by the area under the curve $f(x)$ between $x=a$ and $x=b$.  \n",
    "\n",
    "## The trapezoidal rule\n",
    "\n",
    "Among the simplest ways to evaluate this area numerically is to divide the interval into $N$ uniform slices of width $h=\\frac{b-a}{N}$, approximate the area under the curve in a given slice by the area of a trapezoid, and sum over all trapezoids/slices.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../Images/fig5-1b.png\" width=\"400\"/>\n",
    "     <figcaption>The trapezoidal approximation.</figcaption>\n",
    "</div>\n",
    "\n",
    "Following this method, we first divide the interval into slices with edges at $x$ values given by $x_k = a+kh$.  The area of the $k$th slice can be trivially calculated as $A_k = \\frac{h}{2}[f(x_{k-1}) + f(x_k)]$, where $k \\in [1,N]$.  Summing this over all $N$ slices yields the total integral\n",
    "\\begin{align}\\label{trapezoidal}\\tag{1}\n",
    "    \\int_a^b f(x)\\d x \\approx \\sum_{k=1}^N A_k &= \\frac{h}{2}\\sum_{k=1}^N [f(x_{k-1}) + f(x_k)]\\\\\n",
    "    &= \\frac{h}{2}[f(x_0) + f(x_1) + f(x_1) + f(x_2) + \\cdots + f(x_N)]\\\\\n",
    "    &= \\frac{h}{2}\\left[f(a) + f(b) + 2\\sum_{k=1}^{N-1}f(x_k)\\right]\n",
    "\\end{align}\n",
    "\n",
    "Let's apply this technique to an integral which can be solved analytically, so we can compare our numerical solution to the exact solution.  Consider the integral \\begin{equation}\n",
    "    \\int_{-1}^1 (x^4-2x+1) \\d x = \\left[\\frac{x^5}{5} - x^2 + x \\right]_{-1}^1 = 2.4\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6ec230",
   "metadata": {
    "id": "ce6ec230",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral: 2.4265600000000003\n",
      "Error:1.1067%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define parameters for numerical integration\n",
    "a = -1 # Lower bound\n",
    "b = 1 # Upper bound\n",
    "\n",
    "######################################################\n",
    "\n",
    "def f(x):\n",
    "    return x**4 - 2*x + 1\n",
    "\n",
    "######################################################\n",
    "\n",
    "def trapInt(func, x0, xf, nSlices):\n",
    "    h=(xf-x0)/nSlices\n",
    "    \n",
    "    # Calculate a grid of x values\n",
    "    xk = np.linspace(x0, xf, nSlices+1, float)\n",
    "\n",
    "    # Calculate the corresponding values of f(x)\n",
    "    yk = func(xk)\n",
    "\n",
    "    # Calculate the integral\n",
    "    result = .5*h * (yk[0] + yk[-1] + 2*np.sum(yk[1:-1]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "######################################################\n",
    "\n",
    "integral = trapInt(f, a, b, 10)\n",
    "\n",
    "print(\"Integral:\",integral)\n",
    "print(\"Error:{:.4f}%\".format(100*(integral-2.4)/2.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f0092-fe33-444b-9f0f-7658f0179826",
   "metadata": {},
   "source": [
    "This is not terribly far from the true value, considering the simplicity of the method.  Let's see what happens if we gradually increase the value of $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e928942-c5a0-4b24-b30b-f85497aa7d58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10\n",
      "Integral: 2.4265600000000003\n",
      "Error:1.1067%\n",
      "\n",
      "N: 20\n",
      "Integral: 2.4066600000000005\n",
      "Error:0.2775%\n",
      "\n",
      "N: 50\n",
      "Integral: 2.401066496\n",
      "Error:0.0444%\n",
      "\n",
      "N: 100\n",
      "Integral: 2.400266656\n",
      "Error:0.0111%\n",
      "\n",
      "N: 1000\n",
      "Integral: 2.4000026666656\n",
      "Error:0.0001%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for N in [10, 20, 50, 100, 1000]:\n",
    "    integral = trapInt(f, a, b, N)\n",
    "\n",
    "    print(\"N:\",N)\n",
    "    print(\"Integral:\",integral)\n",
    "    print(\"Error:{:.4f}%\".format(100*(integral-2.4)/2.4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c28223-68e0-44da-926e-01a1e7135bb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "The value of the integral calculated using the trapezoidal rule is converging rather quickly to the true value.\n",
    "\n",
    "### Approximation error\n",
    "\n",
    "Keep in mind that we are summing a large number of floats when we use the trapezoidal rule.  As we learned, this leads to rounding error.  However, the rounding error is generally subdominant to the so-called \"approximation error.\"\n",
    "\n",
    "Let's consider the slice from $x_{k-1}$ to $x_k$ and perform a Taylor expansion of $f(x)$ around $x_{k-1}$:\n",
    "\n",
    "\\begin{align}\n",
    "    f(x) &= \\sum_{n=0}^{\\infty}\\frac{f^{(n)}(x_e)}{n!}(x-x_e)^n\\\\\n",
    "    &= f(x_{k-1}) + f\\p(x_{k-1})(x-x_{k-1}) + \\frac{f^{\\prime\\prime}(x_{k-1})}{2!}(x-x_{k-1})^2 + \\frac{f^{\\prime\\prime\\prime}(x_{k-1})}{3!}(x-x_{k-1})^3 + \\cdots\n",
    "\\end{align}\n",
    "where the prime symbol is used to indicate the derivative with respect to $x$.  Integrating this function from $x_{k-1}$ to $x_k$ yields\n",
    "\n",
    "\\begin{equation}\n",
    "    \\int_{x_{k-1}}^{x_k}f(x)\\d x = f(x_{k-1})\\int_{x_{k-1}}^{x_k}\\d x + f\\p(x_{k-1})\\int_{x_{k-1}}^{x_k}(x-x_{k-1})\\d x + \\frac{f^{\\prime\\prime}(x_{k-1})}{2!}\\int_{x_{k-1}}^{x_k}(x-x_{k-1})^2\\d x + \\frac{f^{\\prime\\prime\\prime}(x_{k-1})}{3!}\\int_{x_{k-1}}^{x_k}(x-x_{k-1})^3\\d x + \\cdots\\\\\n",
    "\\end{equation}\n",
    "\n",
    "After making the substitution $u=x-x_{k-1}$, this yields\n",
    "\\begin{align}\n",
    "\\int_{x_{k-1}}^{x_k}f(x)\\d x &= f(x_{k-1})\\int_0^h\\d u + f\\p(x_{k-1})\\int_0^h u\\d u + \\frac{f^{\\prime\\prime}(x_{k-1})}{2}\\int_0^hu^2\\d u + \\frac{f^{\\prime\\prime\\prime}(x_{k-1})}{6}\\int_0^hu^3\\d u + \\cdots\\\\\n",
    "&= hf(x_{k-1}) + \\frac{h^2}{2}f\\p(x_{k-1}) + \\frac{h^3}{6}f^{\\prime\\prime}(x_{k-1}) + \\frac{h^4}{24}f^{\\prime\\prime\\prime}(x_{k-1}) + \\cdots \\label{taylor1}\\tag{2}\\\\\n",
    "\\end{align}.\n",
    "\n",
    "Performing the same expansion around $x=x_k$ yields\n",
    "\\begin{equation}\n",
    "     \\int_{x_{k-1}}^{x_k}f(x)\\d x = hf(x_{k}) \\color{red}{-} \\frac{h^2}{2}f\\p(x_{k}) + \\frac{h^3}{6}f^{\\prime\\prime}(x_{k}) \\color{red}{-} \\frac{h^4}{24}f^{\\prime\\prime\\prime}(x_{k}) + \\cdots\n",
    "\\label{taylor2}\\tag{3}\\\\\n",
    "\\end{equation}.  \n",
    "The minus signs affecting terms even in $h$ result from the fact that $x-x_k$ is negative, while $x-x_{k-1}$ is positive.\n",
    "\n",
    "\n",
    "Taking the average of Equations 2 and 3 yields\n",
    "\n",
    "\\begin{equation}\n",
    "\\int_{x_{k-1}}^{x_k}f(x)\\d x = \\frac{h}{2}\\left[f(x_{k-1})+f(x_{k})\\right] + \\frac{h^2}{4}\\left[f\\p(x_{k-1})\\color{red}{-}f\\p(x_{k})\\right] + \\frac{h^3}{12}\\left[f^{\\prime\\prime}(x_{k-1})+f^{\\prime\\prime}(x_{k})\\right] + \\frac{h^4}{48}\\left[f^{\\prime\\prime\\prime}(x_{k-1})\\color{red}{-}f^{\\prime\\prime\\prime}(x_{k})\\right] + \\cdots\n",
    "\\end{equation}.\n",
    "\n",
    "Finally, we can sum this expression over all $N$ slices to obtain the desired integral\n",
    "\\begin{align}\n",
    "    \\int_a^b f(x)\\d x &= \\sum_{k=1}^N \\int_{x_{k-1}}^{x_k}f(x)\\d x\\\\\n",
    "    &= \\frac{h}{2}\\color{blue}{\\sum_{k=1}^N}\\left[f(x_{k-1})+f(x_{k})\\right] + \\frac{h^2}{4}\\left[f\\p(a)\\color{red}{-}f\\p(b)\\right] + \\frac{h^3}{12}\\color{blue}{\\sum_{k=1}^N}\\left[f^{\\prime\\prime}(x_{k-1})+f^{\\prime\\prime}(x_{k})\\right] + \\frac{h^4}{48}\\left[f^{\\prime\\prime\\prime}(a)\\color{red}{-}f^{\\prime\\prime\\prime}(b)\\right] + \\cdots\n",
    "\\label{error}\\tag{4}\n",
    "\\end{align}.  For terms even in $h$, the terms in the sum cancel, except for those evaluated at $x=a$ and $x=b$.  Note that this relation is exact provided that we consider all terms in the (infinite) sum.  Fortunately, $h$ is typically a small number, so each term on the right-hand side of Equation 4 should be smaller than all those that preceed it.  Therefore, many of these can be neglected (depending on the desired accuracy).\n",
    "\n",
    "Comparing Equations 1 and 4, we see that the first term on the right-hand side of Equation 4 is the same as the right-hand side of Equation 1.  So, when we use the trapezoidal rule, we are neglecting all but the first term of this infinite series.  The size of these neglected terms are therefore related to the approximation error of the trapezoidal method.\n",
    "\n",
    "Let's examine these terms further.  Consider the integral $\\int_a^b f^{\\prime\\prime}(x)\\d x$.  We can approximate this integral with the trapezoidal rule, by using Equation 1 with the replacement $f(x)\\rightarrow f^{\\prime\\prime}(x)$, which yields\n",
    "\\begin{equation}\n",
    "\\int_a^b f^{\\prime\\prime}(x)\\d x \\approx \\frac{h}{2}\\sum_{k=1}^N [f^{\\prime\\prime}(x_{k-1}) + f^{\\prime\\prime}(x_k)]\n",
    "\\end{equation}.  Aside from a multiplicative constant, this is the same as the third term on the right-hand side of Equation 4.  Let's rearrange (and simplify) this expression, so we can substitute it into Equation 4:\n",
    "\\begin{align}\n",
    "    \\int_a^b f^{\\prime\\prime}(x)\\d x &\\approx \\frac{h}{2}\\sum_{k=1}^N [f^{\\prime\\prime}(x_{k-1}) + f^{\\prime\\prime}(x_k)]\\\\\n",
    "    \\frac{h^2}{6}\\int_a^b f^{\\prime\\prime}(x)\\d x &\\approx \\frac{h^3}{12}\\sum_{k=1}^N\\left[f^{\\prime\\prime}(x_{k-1})+f^{\\prime\\prime}(x_{k})\\right]\\\\\n",
    "    \\frac{h^2}{6} \\left[f\\p(b) - f\\p(a)\\right] &\\approx \\frac{h^3}{12}\\sum_{k=1}^N\\left[f^{\\prime\\prime}(x_{k-1})+f^{\\prime\\prime}(x_{k})\\right]\\\\\n",
    "\\end{align}\n",
    "\n",
    "Substituting the left-hand side of this equation into Equation 4 yields\n",
    "\\begin{equation}\n",
    "     \\int_a^b f(x)\\d x = \\frac{h}{2}\\color{blue}{\\sum_{k=1}^N}\\left[f(x_{k-1})+f(x_{k})\\right] + \\frac{h^2}{12}\\left[f\\p(a)\\color{red}{-}f\\p(b)\\right] + \\frac{h^4}{48}\\left[f^{\\prime\\prime\\prime}(a)\\color{red}{-}f^{\\prime\\prime\\prime}(b)\\right] + \\cdots\n",
    "\\end{equation}\n",
    "\n",
    "Again, the first term in this sum is equal to the right-hand side of Equation 1.  Therefore, the approximation error $\\epsilon$ associated with the trapezoidal method is dominated by the second term\n",
    "\\begin{equation}\\label{epsilon}\\tag{5}\n",
    "    \\epsilon \\approx \\frac{h^2}{12}\\left[f\\p(a)\\color{red}{-}f\\p(b)\\right]\n",
    "\\end{equation}.  Clearly, to minimize the approximation error, we should minimize $h$, which is consistent with our observations above.\n",
    "\n",
    "Returning to our example above, the approximation error would be $\\epsilon \\approx \\frac{h^2}{12}\\left[(4a^3-2)-(4b^3-2)\\right] = \\frac{h^2}{3}\\left[a^3-b^3\\right] = \\frac{h^2}{3}\\left[(-1)^3-1^3\\right] = \\frac{-2h^2}{3}$.  For $N=10$, $h=0.2$ and $\\epsilon \\approx \\frac{-2\\times0.2^2}{3} = -0.0266$, which is almost exactly the difference between our numerical result and the true value.  \n",
    "\n",
    "Keep in mind that we often don't have the functional form $f(x)$, so we can't always apply Equation 5 directly.  We may simply have a collection of data points that we wish to integrate, which is all we need for numerical integration.\n",
    "\n",
    "### Practical application\n",
    "\n",
    "Typically, we will choose some reasonable number of steps $N_1$ and perform numerical integration, resulting in the calculated integral $I_1$.  We then double the number of steps ($N_2=2N_1$) and integrate numerically, obtaining the value $I_2$.  In both cases, we know the error is proportional to $h^2$, so true value of the integral $I$ should be related to our estimates by $I = I_i + ch_i^2$ where $c$ is some unknown constant.  Equating both of these expressions for $I$ gives\n",
    "\\begin{equation}\n",
    "    I_1 + ch_1^2 = I_2 + ch_2^2\n",
    "\\end{equation}\n",
    "or\n",
    "\\begin{equation}\n",
    "    I_2-I_1 = c(h_1^2-h_2^2) = c(4h_2^2-h_2^2)=3ch_2^2\n",
    "\\end{equation}.\n",
    "The error on our second estimate $I_2$ is given by $ch_2^2 = \\frac{1}{3}(I_2-I_1)$, which we can calculate trivially.  If the absolute value of this error is sufficiently small, we're done.  If not, double the number of steps and repeat, until the desired accuracy has been acheived.  This is known as \"adaptive integration.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace79c5-0bfc-42da-88f4-e09f03e43f83",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simpson's rule\n",
    "\n",
    "In effect, the trapezoidal rule approximates the function (within a given slice) as a first-order polynomial (line).  We can uniquely determine the linear function based on any two sample points.  \n",
    "\n",
    "We can improve the accuracy of our approximation by instead approximating the function using a second-order polynomial.  To uniquely determine the second-order polynomial, three sample points are required.  This requires combining adjacent slices, as shown in the Figure below.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../Images/fig5-2.png\" width=\"400\"/>\n",
    "     <figcaption>Simposon's rule.</figcaption>\n",
    "</div>\n",
    "\n",
    "Let's assume we have three sample points at $x=-h, 0, h$.  We can evaluate our polynomial ($Ax^2 + Bx +C$) at these three points:\n",
    "\\begin{align}\n",
    "    f(-h) &= Ah^2 - Bh + C\\\\\n",
    "    f(0)  &= C\\\\\n",
    "    f(h)  &= Ah^2 + Bh + C\\\\\n",
    "\\end{align}.\n",
    "\n",
    "This represents a system of three equations with three unknowns, which can be solved to yield:\n",
    "\\begin{align}\n",
    "    A&=\\frac{1}{h^2}\\left[\\frac{1}{2}f(-h)-f(0)+\\frac{1}{2}f(h)\\right]\\\\\n",
    "    B&=\\frac{1}{2h}\\left[f(h)-f(-h)\\right]\\\\\n",
    "    C&=f(0)\n",
    "\\end{align}.\n",
    "\n",
    "From these relations, we can calculate the integral in this region.\n",
    "\\begin{equation}\n",
    "   \\int_{-h}^h \\left(Ax^2 + Bx+C\\right) = \\left[ \\frac{1}{3}Ax^3+\\frac{1}{2}Bx^2+Cx \\right]_{-h}^h  = \\frac{2}{3}Ah^3+2Ch =\\frac{h}{3}\\left[f(-h)+4f(0)+f(h)\\right]\n",
    "\\end{equation}\n",
    "\n",
    "The above relation gives the approximate integral of $f(x)$ within a given pair of slices.  To get the total integral, we sum this over all pairs of slices.\n",
    "\\begin{equation}\n",
    "    I(a,b) = \\frac{h}{3}\\sum_{\\substack{k=1 \\\\ k\\in\\mathrm{odd}}}^N \\left[ f(x_{n-1}) + 4f(x_n) + f(x_{n+1}) \\right]\n",
    "\\end{equation}.  Expanding the sum yields\n",
    "\\begin{align}\\label{simpson}\\tag{6}\n",
    "    I(a,b) &= \\frac{h}{3}\\left[f(x_{0}) + 4f(x_1) + f(x_{2})\\right] + \\frac{h}{3}\\left[f(x_{2}) + 4f(x_3) + f(x_{4})\\right] + \\frac{h}{3}\\left[ f(x_{4}) + 4f(x_5) + f(x_{6}) \\right] +\\cdots\\\\\n",
    "           &= \\frac{h}{3}\\left[f(x_{0}) + 4f(x_1) + 2f(x_2) + 4f(x_3) + 2f(x_4) + \\cdots\\right] \\\\\n",
    "           &= \\frac{h}{3}\\left[f(a) + f(b) + 4\\sum_{\\substack{k=1 \\\\ k\\in\\mathrm{odd}}}^{N-1}f(a+kh) + 2\\sum_{\\substack{k=2 \\\\ k\\in\\mathrm{even}}}^{N-2}f(a+kh)\\right]\\\\\n",
    "\\end{align}.\n",
    "\n",
    "This relation is known as \"Simpson's rule.\"  It is rather similar to Equation 1, only slightly more complicated.\n",
    "\n",
    "Let's see how the performance of this approximation compares to the trapezoidal rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72b061a-dcb1-4bdc-a5ad-1fe6a76a0df0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10\n",
      "          Trapezoidal       Simpson's         \n",
      "Integral: 2.426560000000    2.400426666667    \n",
      "\n",
      "N: 20\n",
      "          Trapezoidal       Simpson's         \n",
      "Integral: 2.406660000000    2.400026666667    \n",
      "\n",
      "N: 50\n",
      "          Trapezoidal       Simpson's         \n",
      "Integral: 2.401066496000    2.400000682667    \n",
      "\n",
      "N: 100\n",
      "          Trapezoidal       Simpson's         \n",
      "Integral: 2.400266656000    2.400000042667    \n",
      "\n",
      "N: 1000\n",
      "          Trapezoidal       Simpson's         \n",
      "Integral: 2.400002666666    2.400000000004    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def simpInt(func, x0, xf, nSlices):\n",
    "    h=(b-a)/nSlices\n",
    "    \n",
    "    # Calculate a grid of x values\n",
    "    xk = np.linspace(x0, xf, nSlices+1, float)\n",
    "\n",
    "    # Calculate the corresponding values of f(x)\n",
    "    yk = func(xk)\n",
    "\n",
    "    # Calculate the integral\n",
    "    result = (h/3) * (yk[0] + yk[-1] + 4*np.sum(yk[1:-1:2]) + 2*np.sum(yk[2:-1:2]) )   #THIS IS THE ONLY LINE WHICH DIFFERS COMPARED TO TrapInt\n",
    "    \n",
    "    return result\n",
    "\n",
    "for N in [10, 20, 50, 100, 1000]:\n",
    "    integralT = trapInt(f, a, b, N)\n",
    "    integralS = simpInt(f, a, b, N)\n",
    "\n",
    "    print(\"N:\",N)\n",
    "    print(\"{:10}{:18}{:18}\".format(\"\",\"Trapezoidal\",\"Simpson's\"))\n",
    "    print(\"{:10}{:<18.12f}{:<18.12f}\".format(\"Integral:\",integralT, integralS))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018a5f3-e328-4d60-b601-23b3583f5e47",
   "metadata": {
    "tags": []
   },
   "source": [
    "Using Simpson's rule yields more accurate results which converge to the true value for much smaller $N$.  \n",
    "\n",
    "When using Simpson's rule, we can follow an adaptive approach, as discussed above.  In this case, the error is given by $\\epsilon=\\frac{1}{15}(I_2-I_1)$.\n",
    "\n",
    "## Higher-order integration\n",
    "\n",
    "To achieve even faster convergence, we could use a higher-order polynomial to approximate the function $f(x)$ within a given slice.  Using four points, we can uniquely determine a third-order polynomial.  In general, we need $N+1$ points to uniquely determine an $N$th-order polynomial. \n",
    "\n",
    "Regardless of the choice of polynomial order, the procedure is similar.  Simply sum over the values of $f(x_k)$, applying appropriate \"weights\" $w_k$ to each point, then multiply by $h$:\n",
    "\\begin{equation}\\label{weights}\\tag{7}\n",
    "    \\int_a^b f(x)\\d x \\approx h\\sum_{k=1}^Nw_kf(x_k)\n",
    "\\end{equation},\n",
    "where the weights are given by:\n",
    " * For a first-order polynomial, the weights are $\\frac{1}{2}$ for the first and last points, and 1 for all others (see Equation 1).\n",
    " * For a second-order polynomial, the weights are $\\frac{1}{3}$ for the first and last points, and $\\frac{4}{3}$ for odd $k$, and $\\frac{2}{3}$ for even $k$ (see Equation 6).\n",
    " * The weights for third- and fourth-order polynomials are available in the textbook.\n",
    " \n",
    " ### Gaussian quadrature\n",
    "\n",
    "Taking higher-order integration methods to the extreme, we could approximate the entire integrand $f(x)$ with a single polynomial of order $N-1$ (assuming we have $N$ sample points).  By choosing appropriate polynomial coefficients, this function should perfectly reproduce the values $f(x)$ at each of our sample points (but not necesarrily in between).\n",
    "\n",
    "In the context of Gaussian quadrature, degree $N-1$ \"interpolating polynomials\" are used, with the following definition:\n",
    "\\begin{align}%\\label{gauss}\\tag{8}\n",
    "    \\phi_k(x) &= \\prod_{\\substack{m=1\\cdots N \\\\ m\\neq k}}\\frac{x-x_m}{x_k-x_m}\\\\\n",
    "    &=\\frac{x-x_1}{x_k-x_1}\\times\\cdots\\times\\frac{x-x_{k-1}}{x_k-x_{k-1}}\\times\\frac{x-x_{k+1}}{x_k-x_{k+1}}\\times\\cdots\\times\\frac{x-x_N}{x_k-x_N}\n",
    "\\end{align}.  The numerator of these $N$ polynomials contain one factor for each sample point, except $x=x_k$.\n",
    "\n",
    "Let's see if we can simplfy this expression, by evaluating one such polynomial at $x=x_k$:\n",
    "\\begin{align}\n",
    "    \\phi_k(x_k) &= \\frac{x_k-x_1}{x_k-x_1}\\times\\cdots\\times\\frac{x_k-x_{k-1}}{x_k-x_{k-1}}\\times\\frac{x_k-x_{k+1}}{x_k-x_{k+1}}\\times\\cdots\\times\\frac{x_k-x_N}{x_k-x_N}\n",
    "\\end{align}.  Since each term in the product is one, $\\phi_k(x_k)=1$.  \n",
    "\n",
    "Let's also evaluate $\\phi_k(x)$ at $x=x_{k+1}$:\n",
    "\\begin{align}\n",
    "    \\phi_k(x_{k+1}) &= \\frac{x_{k+1}-x_1}{x_k-x_1}\\times\\cdots\\times\\frac{x_{k+1}-x_{k-1}}{x_k-x_{k-1}}\\times\\frac{\\color{blue}{x_{k+1}-x_{k+1}}}{x_k-x_{k+1}}\\times\\cdots\\times\\frac{x_{k+1}-x_N}{x_k-x_N}\n",
    "\\end{align}. Exactly one term in the product is now zero, making $\\phi_k(x_{k+1})=0$.  The same holds true for all other sample points (with $m\\neq k$).  Thus, $\\phi_k(x_m) = \\delta_{km}$, \n",
    "where $\\delta_{km}$ is the Kronecker delta function (which equals one when $k=m$ and zero otherwise).\n",
    "\n",
    "Now consider the function $\\Phi(x) = \\sum_{k=1}^Nf(x_k)\\phi_k(x)$.  Evaluating this function at a particular sample point $x=x_m$, yields\n",
    "\\begin{align}\n",
    "    \\Phi(x_m) &= \\sum_{k=1}^Nf(x_k)\\phi_k(x_m) = \\sum_{k=1}^Nf(x_k)\\delta_{km} = f(x_m)\n",
    "\\end{align}.\n",
    "This holds for any given sample point $x_m$, so the function $\\Phi(x)$ perfectly reproduces the values of the integrand $f(x)$ at all sample points.\n",
    "\n",
    "Given the function $\\Phi(x)$, we can simply integrate it from $x=a$ to $x=b$ to obtain the approximate integral of $f(x)$:\n",
    "\\begin{align}\\tag{8}\n",
    "    \\int_a^bf(x)\\d x \\approx \\int_a^b\\Phi(x)\\d x = \\int_a^b \\sum_{k=1}^Nf(x_k)\\phi_k(x) \\d x = \\sum_{k=1}^N f(x_k) \\int_a^b \\phi_k(x) \\d x\n",
    "\\end{align}.  Thus, the problem has been reduced to a series of integrals over the interpolating polynomials.\n",
    "\n",
    "Unfortunately, no general closed-form expression for the integral of the interpolating polynomials exists, and we are forced to resort to other numerical integration methods to perform these integrals.  However, note that these integrals depend only on the location of sample points $x_k$, and not the function $f(x)$ that we actually wish to integrate.  Once the integrals of the interpolating polynomials have been calculated, the results can be used to perform integration of many different functions $f(x)$.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Let's apply Gaussian quadrature to integrate our example function $f(x)=x^4-2x+1$.  First, we calculate the interpolating polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369a5fe-c159-4965-9e8b-60c2ce624757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#phi_k(x) given a grid of x_k values\n",
    "def phi_k(x, k, xk):\n",
    "    result = 1\n",
    "    \n",
    "    for m,xm in enumerate(xk):\n",
    "        if m==k: continue\n",
    "        result *= (x - xm)/(xk[k] - xm)\n",
    "\n",
    "    return result\n",
    "\n",
    "#############################################\n",
    "\n",
    "N = 5   #only 5 sample points at x = -1, -0.5, 0, 0.5, 1\n",
    "\n",
    "xk = np.linspace(a, b, N, float)   \n",
    "denseXValues = np.linspace(a, b, 1000, float)   #for plotting purposes only\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(denseXValues, phi_k(denseXValues, 0, xk), label=\"$k=0$\")\n",
    "plt.plot(denseXValues, phi_k(denseXValues, 1, xk), label=\"$k=1$\")\n",
    "plt.plot(denseXValues, phi_k(denseXValues, 2, xk), label=\"$k=2$\")\n",
    "plt.plot(denseXValues, phi_k(denseXValues, 3, xk), label=\"$k=3$\")\n",
    "plt.plot(denseXValues, phi_k(denseXValues, 4, xk), label=\"$k=4$\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$\\phi_k(x)$\")\n",
    "plt.xticks(xk)\n",
    "plt.yticks([0,1])\n",
    "plt.grid(True, which='major', axis='both')\n",
    "plt.legend(loc='upper right', fontsize='large')\n",
    "plt.ylim(-.6, 2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc707598-634d-48b6-9310-eca8ca10424a",
   "metadata": {},
   "source": [
    "As claimed, each of the $\\phi_k(x)$ are equal to one when evaluated at $x=x_k$ and zero for all other sample points.  \n",
    "\n",
    "Now, let's compare our order $N-1$ polynomial $\\Phi(x) = \\sum_{k=1}^Nf(x_k)\\phi_k(x)$ to the integrand $f(x)$ that we wish to approximate, over the entire range of integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc1d75-842c-4b73-93b6-5febc82311ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Phi = 0\n",
    "for k in range(N):\n",
    "    Phi += f(denseXValues)*phi_k(denseXValues, k, xk)\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(denseXValues, Phi, label=\"$\\Phi(x)$\")\n",
    "plt.plot(denseXValues, f(denseXValues), linestyle='dashed', label=\"$f(x)$\")\n",
    "\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.legend(loc='upper left', fontsize='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c56f7-c13a-4075-adc5-3990d6cbfd5c",
   "metadata": {},
   "source": [
    "In this case, $\\Phi(x)$ perfectly (within machine precision) reproduces the integrand $f(x)$.  This is expected, provided $f(x)$ is a polynomial of order $N-1$ or lower.  For other cases, $\\Phi(x)$ merely approximates $f(x)$.\n",
    "\n",
    "Next, we can integrate the interpolating polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8c630-206d-4574-b92f-db2f3a0ddbc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "polyInt = []\n",
    "for k in range(N):\n",
    "    \n",
    "    #define a new function which takes a single argument x, since this is what is expected by simpInt\n",
    "    def phi(x):\n",
    "        return phi_k(x, k, xk)\n",
    "    \n",
    "    polyInt.append(simpInt(phi, a, b, 10))   #just 10 sample points for integration of interpolating polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ae83ad-e3bd-4974-a38c-06a947914ca5",
   "metadata": {},
   "source": [
    "Finally, calculate the integral of our function using Equation 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3926f3a0-615a-4803-9a08-c5ea0034ec92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "I = 0\n",
    "for k in range(N):\n",
    "    I += f(xk[k]) * polyInt[k]\n",
    "    \n",
    "I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96464b-74f1-4ce8-8ff9-a78aca739d5f",
   "metadata": {},
   "source": [
    "As a reminder, the true value of this integral is 2.4.  We were able to obtain a fairly precise result with just 10 sample points for the integration of the interpolating polynomials.\n",
    "\n",
    "If we want to integrate another function, $f_2(x) = 5x^3 - 18x^2$, over the same domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a98806-eb9b-4c77-a909-e61e99bb61a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    return 5*x**3 - 18*x**2\n",
    "\n",
    "I = 0\n",
    "for k in range(N):\n",
    "    I += f2(xk[k]) * polyInt[k]\n",
    "    \n",
    "I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180da1f-5c6e-4a16-9553-064377e0d793",
   "metadata": {},
   "source": [
    "The true value of this integral is -12.  Our result is quite precise, with minimal effort.\n",
    "\n",
    "With just slightly more effort, we can perform integrals over another domain of integration.  For alternative domains of integration, we must rescale the integrals of the interpolating polynomials by the factor $\\frac{1}{2}\\left(b-a\\right)$.\n",
    "\n",
    "Let's integrate $f_2(x)$ over the range $x=10$ to $x=15$, using the integrals of the interpolating polynomials we calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8aa396-a229-4e0d-9c35-1e360f6ad3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aPrime=10\n",
    "bPrime=15\n",
    "\n",
    "#xkPrime = .5*(bPrime-aPrime)*xk + .5*(bPrime+aPrime)\n",
    "xkPrime = np.linspace(aPrime, bPrime, N, float)   \n",
    "\n",
    "I = 0\n",
    "for k in range(N):\n",
    "    I += f2(xkPrime[k]) * .5*(bPrime-aPrime)*polyInt[k]   #reusing the same integrals of the interpolating polynomials over the original domain calculated above\n",
    "    \n",
    "I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7d9ad-89f1-4d9e-9639-b77f14ebd655",
   "metadata": {},
   "source": [
    "The true value of this integral is 36531.3, very close to the value we calculated with just a few lines of code.\n",
    "\n",
    "## Integrals over an infinite range\n",
    "\n",
    "Often, we need to perform integrals which extend to $x=\\pm\\infty$, which can be calculated using the same techniques as above.  We must simply perform a change of variables, defining $z=\\frac{x}{1+x}$.  In terms of $z$, $x$ is given by $\\frac{z}{1-z}$, and $\\d x=\\frac{\\d z}{(1-z)^2}$.  With these definitions, we can recast our integral over an infinite range to an integral over a finite domain.  \n",
    "\n",
    "For example, let's assume we wish to integrate some function $f(x)$ from zero to $\\infty$:\n",
    "\\begin{equation}\n",
    "    \\int_0^{\\infty} f(x)\\d x = \\int_0^1 \\frac{1}{\\left(1-z\\right)^2}f\\left(\\frac{z}{1-z}\\right)\\d z\n",
    "\\end{equation}.  The right-hand side of this equation can be evaluated using the techniques discussed above.\n",
    "\n",
    "## Integrals with non-uniform sample points\n",
    "\n",
    "So far, we have used an evenly spaced grid of sample points to perform our integrals.  However, this is not required.  In fact, to obtain the highest precision possible with Gaussian quadrature, we should choose our sample points to coincide with the zeros of the $N$th Legendre polynomial.  A detailed discussion of this topic is beyond the scope of the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fffd65-6873-4292-9011-1fa3ac8608ac",
   "metadata": {
    "id": "7aJ-5EGxdb0V"
   },
   "source": [
    "## Integration with SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda5b4f4-8507-472d-9052-f44de452b99a",
   "metadata": {
    "id": "o6RR_Ekqexov"
   },
   "source": [
    "Now that we know how to do numerical integration \"by hand,\" we should also be aware that there are python libraries that can do this for us!  Information on these tools can be found here:\n",
    " * https://docs.scipy.org/doc/scipy/tutorial/integrate.html\n",
    " * https://docs.scipy.org/doc/scipy/reference/integrate.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc8038-4405-4942-81d6-1814eaa9768d",
   "metadata": {
    "id": "a9pijPAvd9tV"
   },
   "source": [
    "The main SciPy function used for integration is `quad()`.  It requires a fit function, the bounds of integration, and (optionally) a desired tolerance.  It uses 9 different methods and attempts to find an estimated integral within the error tolerance requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe6cac-e12f-481d-a3c7-c945820df934",
   "metadata": {
    "id": "8a844869",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.integrate as integrate\n",
    "\n",
    "integral,error = integrate.quad(f, -1, 1)\n",
    "\n",
    "print(\"Integral:\",integral)\n",
    "print(\"Error:\",error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abbbb3-91b3-4bbf-a907-d581ab414f4e",
   "metadata": {},
   "source": [
    "For fit functions with multiple paramters, the parameter values should be passed to the `quad()` function via the `args` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a185e37-68f4-4f60-bf40-db886bfb80d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#phi_k(x, k, xk)\n",
    "\n",
    "integral,error = integrate.quad(phi_k, -1, 1, args=(1,xk))\n",
    "\n",
    "print(\"Integral:\",integral)\n",
    "print(\"Error:\",error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da773c7-03d9-4d42-aa94-3a1098d866d8",
   "metadata": {},
   "source": [
    "We can also use SciPy to perform two-dimensional integrals, using the `dblquad()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76444b36-f087-4412-beed-1a207d63860c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f2D(x,y):\n",
    "    return x*(y**2)\n",
    "    \n",
    "integral,error = integrate.dblquad(f2D, 0, 2, 0, 2)\n",
    "\n",
    "print(\"Integral:\",integral)\n",
    "print(\"Error:\",error)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
